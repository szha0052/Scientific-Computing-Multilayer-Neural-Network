{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b954ab5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from MLP.model import MLP\n",
    "import pandas as pd\n",
    "from MLP.layers import SoftmaxCrossEntropy\n",
    "\n",
    "# 导入npy数据集\n",
    "X_train = np.load('Assignment1-Dataset/train_data.npy')\n",
    "X_test = np.load('Assignment1-Dataset/test_data.npy')\n",
    "Y_train = np.load('Assignment1-Dataset/train_label.npy').flatten()\n",
    "Y_test = np.load('Assignment1-Dataset/test_label.npy').flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00ce8560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 128), (50000,), (10000, 128), (10000,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, Y_train.shape, X_test.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4fe16aa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 统计数据集的类别\n",
    "classes = np.unique(Y_train)\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa98f263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 2.1379\n",
      "Epoch 2/100, Loss: 1.9578\n",
      "Epoch 3/100, Loss: 1.8820\n",
      "Epoch 4/100, Loss: 1.8338\n",
      "Epoch 5/100, Loss: 1.8003\n",
      "Epoch 6/100, Loss: 1.7774\n",
      "Epoch 7/100, Loss: 1.7564\n",
      "Epoch 8/100, Loss: 1.7398\n",
      "Epoch 9/100, Loss: 1.7217\n",
      "Epoch 10/100, Loss: 1.7081\n",
      "Epoch 11/100, Loss: 1.6948\n",
      "Epoch 12/100, Loss: 1.6839\n",
      "Epoch 13/100, Loss: 1.6747\n",
      "Epoch 14/100, Loss: 1.6691\n",
      "Epoch 15/100, Loss: 1.6579\n",
      "Epoch 16/100, Loss: 1.6537\n",
      "Epoch 17/100, Loss: 1.6442\n",
      "Epoch 18/100, Loss: 1.6400\n",
      "Epoch 19/100, Loss: 1.6335\n",
      "Epoch 20/100, Loss: 1.6315\n",
      "Epoch 21/100, Loss: 1.6230\n",
      "Epoch 22/100, Loss: 1.6184\n",
      "Epoch 23/100, Loss: 1.6117\n",
      "Epoch 24/100, Loss: 1.6095\n",
      "Epoch 25/100, Loss: 1.6030\n",
      "Epoch 26/100, Loss: 1.5998\n",
      "Epoch 27/100, Loss: 1.5935\n",
      "Epoch 28/100, Loss: 1.5878\n",
      "Epoch 29/100, Loss: 1.5876\n",
      "Epoch 30/100, Loss: 1.5832\n",
      "Epoch 31/100, Loss: 1.5792\n",
      "Epoch 32/100, Loss: 1.5739\n",
      "Epoch 33/100, Loss: 1.5746\n",
      "Epoch 34/100, Loss: 1.5639\n",
      "Epoch 35/100, Loss: 1.5659\n",
      "Epoch 36/100, Loss: 1.5596\n",
      "Epoch 37/100, Loss: 1.5626\n",
      "Epoch 38/100, Loss: 1.5571\n",
      "Epoch 39/100, Loss: 1.5572\n",
      "Epoch 40/100, Loss: 1.5530\n",
      "Epoch 41/100, Loss: 1.5464\n",
      "Epoch 42/100, Loss: 1.5499\n",
      "Epoch 43/100, Loss: 1.5482\n",
      "Epoch 44/100, Loss: 1.5439\n",
      "Epoch 45/100, Loss: 1.5412\n",
      "Epoch 46/100, Loss: 1.5409\n",
      "Epoch 47/100, Loss: 1.5382\n",
      "Epoch 48/100, Loss: 1.5356\n",
      "Epoch 49/100, Loss: 1.5384\n",
      "Epoch 50/100, Loss: 1.5323\n",
      "Epoch 51/100, Loss: 1.5344\n",
      "Epoch 52/100, Loss: 1.5264\n",
      "Epoch 53/100, Loss: 1.5288\n",
      "Epoch 54/100, Loss: 1.5269\n",
      "Epoch 55/100, Loss: 1.5259\n",
      "Epoch 56/100, Loss: 1.5189\n",
      "Epoch 57/100, Loss: 1.5229\n",
      "Epoch 58/100, Loss: 1.5200\n",
      "Epoch 59/100, Loss: 1.5199\n",
      "Epoch 60/100, Loss: 1.5141\n",
      "Epoch 61/100, Loss: 1.5163\n",
      "Epoch 62/100, Loss: 1.5130\n",
      "Epoch 63/100, Loss: 1.5108\n",
      "Epoch 64/100, Loss: 1.5087\n",
      "Epoch 65/100, Loss: 1.5123\n",
      "Epoch 66/100, Loss: 1.5088\n",
      "Epoch 67/100, Loss: 1.5093\n",
      "Epoch 68/100, Loss: 1.5034\n",
      "Epoch 69/100, Loss: 1.5081\n",
      "Epoch 70/100, Loss: 1.5083\n",
      "Epoch 71/100, Loss: 1.5040\n",
      "Epoch 72/100, Loss: 1.5003\n",
      "Epoch 73/100, Loss: 1.5041\n",
      "Epoch 74/100, Loss: 1.5005\n",
      "Epoch 75/100, Loss: 1.5011\n",
      "Epoch 76/100, Loss: 1.4945\n",
      "Epoch 77/100, Loss: 1.4954\n",
      "Epoch 78/100, Loss: 1.4971\n",
      "Epoch 79/100, Loss: 1.4959\n",
      "Epoch 80/100, Loss: 1.4978\n",
      "Epoch 81/100, Loss: 1.4954\n",
      "Epoch 82/100, Loss: 1.4910\n",
      "Epoch 83/100, Loss: 1.4901\n",
      "Epoch 84/100, Loss: 1.4920\n",
      "Epoch 85/100, Loss: 1.4919\n",
      "Epoch 86/100, Loss: 1.4883\n",
      "Epoch 87/100, Loss: 1.4859\n",
      "Epoch 88/100, Loss: 1.4852\n",
      "Epoch 89/100, Loss: 1.4840\n",
      "Epoch 90/100, Loss: 1.4862\n",
      "Epoch 91/100, Loss: 1.4879\n",
      "Epoch 92/100, Loss: 1.4858\n",
      "Epoch 93/100, Loss: 1.4850\n",
      "Epoch 94/100, Loss: 1.4859\n",
      "Epoch 95/100, Loss: 1.4812\n",
      "Epoch 96/100, Loss: 1.4797\n",
      "Epoch 97/100, Loss: 1.4826\n",
      "Epoch 98/100, Loss: 1.4761\n",
      "Epoch 99/100, Loss: 1.4768\n",
      "Epoch 100/100, Loss: 1.4794\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 超参数\n",
    "input_dim = 128  # 输入数据维度\n",
    "hidden_dims = [64, 32]  # 隐藏层维度\n",
    "output_dim = 10  # 输出类别数（例如10分类）\n",
    "learning_rate = 0.001\n",
    "momentum = 0.9\n",
    "num_epochs = 100\n",
    "batch_size = 32\n",
    "\n",
    "# 创建MLP模型\n",
    "model = MLP(input_dim, hidden_dims, output_dim, dropout_rate=0.2, weight_decay=1e-4)\n",
    "\n",
    "# 初始化动量优化需要的速度\n",
    "velocity = {}\n",
    "\n",
    "# 训练循环\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    for i in range(0, len(X_train), batch_size):\n",
    "        X_batch = X_train[i:i+batch_size]\n",
    "        Y_batch = Y_train[i:i+batch_size]\n",
    "\n",
    "        Y_batch_one_hot = np.eye(output_dim)[Y_batch]\n",
    "        # 32X10的one-hot编码\n",
    "        # 前向传播\n",
    "        logits = model.forward(X_batch, training=True)\n",
    "        \n",
    "        # 计算损失\n",
    "        loss = model.compute_loss(logits, Y_batch_one_hot)\n",
    "        epoch_loss += loss\n",
    "        \n",
    "        # 反向传播\n",
    "        model.backward()\n",
    "        \n",
    "        # 更新参数\n",
    "        model.update(learning_rate, momentum, velocity)\n",
    "    \n",
    "    # 打印每个epoch的损失\n",
    "    avg_loss = epoch_loss / (len(X_train) // batch_size)\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab119ed4",
   "metadata": {},
   "source": [
    "$$ y = \\frac{x - \\mathrm{E}[x]}{\\sqrt{\\mathrm{Var}[x] + \\epsilon}} * \\gamma + \\beta $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0aeccea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Test Accuracy: 52.88%\n"
     ]
    }
   ],
   "source": [
    "predictions_train = model.predict_and_evaluate(X_train, Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "516ebbc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Test Accuracy: 49.70%\n"
     ]
    }
   ],
   "source": [
    "predictions_test = model.predict_and_evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d541ae2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CXXA1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
